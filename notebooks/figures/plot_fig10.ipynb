{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topological clustering analysis - information maps\n",
    "\n",
    "Self-organised feature maps in the final layer representing specific convex boundary elements after network training.\n",
    "\n",
    "This plots Fig 10 and supplementary S2 Fig.\n",
    "\n",
    "**Dependencies**\n",
    "\n",
    "Note that if an inference recording has already been saved to disk, then the workflow skips this file.\n",
    "\n",
    "- `./scripts/run_main_workflow.py experiments/n3p2/train_n3p2_lrate_0_04_181023 31 --chkpt -1 --rule inference -v`\n",
    "- `./scripts/run_main_workflow.py experiments/n4p2/train_n4p2_lrate_0_02_181023 15 --chkpt -1 --rule inference -v`\n",
    "\n",
    "**Plots**\n",
    "\n",
    "- N3P2 feature map (convex- or concave-selective neurons)\n",
    "- N4P2 feature map (convex- or concave-selective neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from pydantic import BaseModel\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from hsnn import analysis, utils, viz\n",
    "from hsnn.analysis import measures\n",
    "from hsnn.utils import handler, io\n",
    "from hsnn.utils.data import ImageSet\n",
    "from hsnn.utils.handler import TrialView\n",
    "\n",
    "OUTPUT_DIR = io.BASE_DIR / \"out/figures/fig10\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "class DataSet(Enum):\n",
    "    N3P2 = 1\n",
    "    N4P2 = 2\n",
    "\n",
    "\n",
    "def load_inference_results(\n",
    "    trial: TrialView, chkpt: int | None, **kwargs\n",
    ") -> xr.DataArray:\n",
    "    results_path = handler.get_results_path(trial, chkpt, **kwargs)\n",
    "    if results_path.is_file():\n",
    "        print(f\"Loading '{results_path}'...\")\n",
    "        return utils.io.load_pickle(results_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"'{results_path}'\")\n",
    "\n",
    "\n",
    "class InferenceConfig(BaseModel):\n",
    "    \"\"\"Inference kwargs passed to `handler.load_results`.\"\"\"\n",
    "\n",
    "    amplitude: int\n",
    "    subdir: str | None = None\n",
    "\n",
    "\n",
    "viz.setup_journal_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load N3P2 and N4P2 recorded results\n",
    "\n",
    "**Get representative Trial per (`E2E`, `FF`) combination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment data structures\n",
    "logdirs = {\n",
    "    DataSet.N3P2: \"n3p2/train_n3p2_lrate_0_04_181023\",\n",
    "    DataSet.N4P2: \"n4p2/train_n4p2_lrate_0_02_181023\",\n",
    "}\n",
    "imagesets: dict[DataSet, tuple[ImageSet, pd.DataFrame]] = {}\n",
    "\n",
    "# Trial data structures\n",
    "dataset_trial_mapping = {\n",
    "    DataSet.N3P2: (20, 20, 7),\n",
    "    DataSet.N4P2: (20, 20, 3),\n",
    "}\n",
    "state_chkpt_mapping = {\"post\": -1}\n",
    "records_ds: dict[DataSet, dict[str, xr.DataArray]] = {\n",
    "    dataset: {\"post\": None} for dataset in DataSet\n",
    "}\n",
    "\n",
    "inference_cfg = InferenceConfig(amplitude=0, subdir=None)\n",
    "offset = 0.0 if inference_cfg.subdir == \"onsets\" else 50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, logdir in logdirs.items():\n",
    "    expt = handler.ExperimentHandler(logdir)\n",
    "    dataset_name = expt.logdir.parent.stem\n",
    "    trial = expt[dataset_trial_mapping[dataset]]\n",
    "    # Recordings per state\n",
    "    for state, chkpt in state_chkpt_mapping.items():\n",
    "        records_ds[dataset][state] = load_inference_results(\n",
    "            trial, chkpt, **dict(inference_cfg)\n",
    "        )\n",
    "    # Imagesets\n",
    "    cfg = trial.config\n",
    "    if inference_cfg.amplitude > 0:\n",
    "        cfg[\"training\"][\"data\"][\"transforms\"][\"gaussiannoise\"] = [\n",
    "            inference_cfg.amplitude\n",
    "        ]\n",
    "    imagesets[dataset] = utils.io.get_dataset(\n",
    "        cfg[\"training\"][\"data\"], return_annotations=True\n",
    "    )\n",
    "else:\n",
    "    # Common parameters\n",
    "    duration: float = (\n",
    "        records_ds[dataset][\"post\"].item(0).duration - offset\n",
    "    )  # Observation period\n",
    "    reps = len(records_ds[dataset][\"post\"][\"rep\"])\n",
    "    input_shape = tuple(cfg[\"topology\"][\"poisson\"][\"EXC\"])\n",
    "    layer_shape = tuple(cfg[\"topology\"][\"spatial\"][\"EXC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Plot information maps for each dataset\n",
    "\n",
    "First get the coordinates of informative neurons\n",
    "\n",
    "Requires pip package: `alphashape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphashape\n",
    "from scipy.interpolate import splev, splprep\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "\n",
    "def get_coordinates_values(\n",
    "    records: xr.DataArray,\n",
    "    labels: pd.DataFrame,\n",
    "    threshold: float,\n",
    "    duration: float,\n",
    "    offset: float,\n",
    "    layer: int = 4,\n",
    "    target: int = 1,\n",
    ") -> tuple[dict[str, np.ndarray], dict[str, np.ndarray]]:\n",
    "    \"\"\"Gets the coordinates of informative neurons, along with their associated specific information\n",
    "    measures, for each side of objects annotated by labels. Coordinates are given as [(x, y), ...].\n",
    "\n",
    "    Returns:\n",
    "        tuple[dict[str, np.ndarray], dict[str, np.ndarray]]: coordinates and associated specific measures.\n",
    "    \"\"\"\n",
    "    rates_array = analysis.infer_rates(\n",
    "        records.sel(layer=layer, nrn_cls=\"EXC\"), duration, offset\n",
    "    )\n",
    "    sides = list(labels.columns[1:])\n",
    "\n",
    "    coordinates: dict[str, np.ndarray] = {}\n",
    "    values: dict[str, np.ndarray] = {}\n",
    "    for side in sides:\n",
    "        specific_measures = measures.get_sorted_measures_rates(\n",
    "            rates_array, labels, side, target\n",
    "        )\n",
    "        indices = specific_measures[specific_measures[\"measure\"] > threshold].index\n",
    "        values[side] = np.asarray(specific_measures.loc[indices][\"measure\"])\n",
    "        _coords = []\n",
    "        for i, index in enumerate(indices):\n",
    "            y, x = np.unravel_index(index, layer_shape)\n",
    "            _coords.append((x, y))\n",
    "        coordinates[side] = np.array(_coords)\n",
    "    return coordinates, values\n",
    "\n",
    "\n",
    "# Function to plot the smoothed alpha shapes of clusters with borders only\n",
    "def plot_smooth_alpha_shapes(axes, points, color, alpha=0.5):\n",
    "    if len(points) >= 3:  # AlphaShape requires at least 3 points\n",
    "        alpha_shape = alphashape.alphashape(points, alpha)\n",
    "        if isinstance(\n",
    "            alpha_shape, (Polygon, MultiPolygon)\n",
    "        ):  # Check if the alpha shape is a valid polygon or multipolygon\n",
    "            if isinstance(alpha_shape, Polygon):\n",
    "                smooth_plot(axes, alpha_shape.exterior.xy, color)\n",
    "                # add_annotation(axes, alpha_shape.centroid, side)\n",
    "            else:\n",
    "                for geom in alpha_shape.geoms:\n",
    "                    smooth_plot(axes, geom.exterior.xy, color)\n",
    "                    # add_annotation(axes, geom.centroid, side)\n",
    "\n",
    "\n",
    "# Function to plot the smoothed polygon with borders only\n",
    "def smooth_plot(axes, xy, color):\n",
    "    x, y = xy\n",
    "    tck, u = splprep([x, y], s=0.0, per=True)\n",
    "    u_new = np.linspace(u.min(), u.max(), 1000)\n",
    "    x_new, y_new = splev(u_new, tck)\n",
    "    axes.fill(\n",
    "        x_new, y_new, color=color, alpha=0.7\n",
    "    )  # Use plot instead of fill for borders only\n",
    "    axes.plot(\n",
    "        x_new, y_new, color=\"black\", linestyle=\"-\", linewidth=0.5\n",
    "    )  # Use a solid black line for borders\n",
    "\n",
    "\n",
    "# Function to add annotations\n",
    "def add_annotation(axes, centroid, side):\n",
    "    axes.text(\n",
    "        centroid.x,\n",
    "        centroid.y,\n",
    "        side,\n",
    "        fontsize=12,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        color=\"black\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common setup\n",
    "state = \"post\"\n",
    "layer = 4\n",
    "threshold = 2 / 3\n",
    "target = 0  # Set target=1 for convex, or target=0 for concave\n",
    "\n",
    "coordinates_ds: dict[DataSet, dict[str, np.ndarray]] = {}\n",
    "values_ds: dict[DataSet, dict[str, np.ndarray]] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get informative neurons per dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in tqdm(DataSet):\n",
    "    records = records_ds[dataset][state]\n",
    "    _, labels = imagesets[dataset]\n",
    "\n",
    "    coordinates_ds[dataset], values_ds[dataset] = get_coordinates_values(\n",
    "        records, labels, threshold, duration, offset, layer, target\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot information maps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes_grid = plt.subplots(1, 2, figsize=(5.5, 3), sharex=False, sharey=False)\n",
    "\n",
    "for i, dataset in enumerate(DataSet):\n",
    "    axes = axes_grid[i]\n",
    "    _, labels = imagesets[dataset]\n",
    "    sides = list(labels.columns[1:])\n",
    "\n",
    "    # Plot information map\n",
    "    color_cycler = plt.rcParams[\"axes.prop_cycle\"]\n",
    "    colors = [elem[\"color\"] for elem in color_cycler]\n",
    "\n",
    "    # Set the background color to a specific grayscale value\n",
    "    axes.set_facecolor(\"0.7\")\n",
    "\n",
    "    for idx, side in enumerate(sides):\n",
    "        points = np.array(coordinates_ds[dataset][side])\n",
    "        plot_smooth_alpha_shapes(\n",
    "            axes, points, color=colors[idx], alpha=(0.15 if target == 0 else 0.2)\n",
    "        )\n",
    "\n",
    "    axes.xaxis.set_major_locator(MaxNLocator(nbins=4))\n",
    "    axes.yaxis.set_major_locator(MaxNLocator(nbins=4))\n",
    "    axes.set_xlabel(\"X\")\n",
    "    if i == 0:\n",
    "        axes.set_ylabel(\"Y\", rotation=0, labelpad=10)\n",
    "    axes.invert_yaxis()\n",
    "    axes.set_title(f\"Information map: {dataset.name}\", size=\"large\", fontweight=\"bold\")\n",
    "f.tight_layout()\n",
    "\n",
    "fname = (\n",
    "    \"fig_information_maps_convex.pdf\"\n",
    "    if target == 1\n",
    "    else \"fig_information_maps_concave.pdf\"\n",
    ")\n",
    "viz.save_figure(f, OUTPUT_DIR / fname, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual neuron coordinates per side as a separate colour\n",
    "f, axes = plt.subplots(figsize=(4, 4))\n",
    "axes: plt.Axes\n",
    "for side, coords in coordinates_ds[dataset].items():\n",
    "    axes.scatter(coords[:, 0], coords[:, 1])\n",
    "axes.invert_yaxis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
