{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resilience of the network to input noise\n",
    "\n",
    "Network robustness to Gaussian input noise measured using single neuron information analysis.\n",
    "\n",
    "**Objectives**\n",
    "\n",
    "- Measure information conveyed by single L4 neurons regarding a left-convex boundary element\n",
    "- Compare the network performance across increasing levels of noise\n",
    "- Compare pre- vs. post-trained networks for N4P2 datasets\n",
    "\n",
    "**Dependencies:**\n",
    "\n",
    "---\n",
    "\n",
    "A) Gather inference spike recordings with noise:\n",
    "- Inference spike recordings for N4P2: both before and after network training\n",
    "- Depends on N4P2 workflows (with and without the `--chkpt -1` argument):\n",
    "```bash\n",
    "./scripts/run_main_workflow.py experiments/n4p2/train_n4p2_lrate_0_02_181023 3 7 15 --rule inference -v\n",
    "\n",
    "for noise in 10 20; do\n",
    "    ./scripts/run_main_workflow.py experiments/n4p2/train_n4p2_lrate_0_02_181023 3 7 15 --rule inference --subdir noise --noise $noise -v\n",
    "done\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "B) Compute information measures:\n",
    "\n",
    "i) For N4P2 (left-convex selectivity):\n",
    "```bash\n",
    "./scripts/figures/compute_information.py ./experiments/n4p2/train_n4p2_lrate_0_02_181023 ALL --side left\n",
    "```\n",
    "i) For N4P2 (left-convex selectivity) with increasing levels of noise:\n",
    "```bash\n",
    "for noise in 10 20; do\n",
    "    ./scripts/figures/compute_information.py ./experiments/n4p2/train_n4p2_lrate_0_02_181023 ALL --analysis noise --side left --subdir noise --noise $noise\n",
    "done\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Figures**\n",
    "\n",
    "- Figure 1: information plots: increasing noise for each of the two datasets\n",
    "- Figure 2: number of selective neurons (exceeding a threshold of 2/3 bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "from hsnn import utils, viz\n",
    "from hsnn.utils import handler, io\n",
    "\n",
    "pidx = pd.IndexSlice\n",
    "RESULTS_DIR = io.BASE_DIR / \"out/figures/information\"\n",
    "OUTPUT_DIR = io.BASE_DIR / \"out/figures/fig11\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class DataSet(Enum):\n",
    "    N3P2 = 1\n",
    "    N4P2 = 2\n",
    "\n",
    "\n",
    "viz.setup_journal_env()\n",
    "\n",
    "\n",
    "def load_measures(\n",
    "    results_dir: Path, noise: int = 0\n",
    ") -> dict[str, dict[str, np.ndarray]]:\n",
    "    \"\"\"Loads ranked single neuron information measures.\n",
    "\n",
    "    Args:\n",
    "        results_dir (Path): Location of pre-computed measures.\n",
    "        noise (int, optional): Noise amplitude of inference recordings. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, dict[str, np.ndarray]]: Mapping from network architecture, and then state.\n",
    "        Each element is an NDArray[float] of ranked measures, shape (num_trials x num_sides, num_nrns)\n",
    "    \"\"\"\n",
    "    fname = io.formatted_name(\"information_left_convex\", \"pkl\", noise=noise)\n",
    "    print(f\"Loading inference recordings from '{results_dir / fname}'\")\n",
    "    return io.load_pickle(results_dir / fname)\n",
    "\n",
    "\n",
    "def load_inference_results(\n",
    "    trial: handler.TrialView, chkpt: int | None, **kwargs\n",
    ") -> xr.DataArray:\n",
    "    results_path = handler.get_results_path(trial, chkpt, **kwargs)\n",
    "    if results_path.is_file():\n",
    "        print(f\"Loading '{results_path}'...\")\n",
    "        return io.load_pickle(results_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"'{results_path}'\")\n",
    "\n",
    "\n",
    "def plot_grid(\n",
    "    state_measures_map: dict, axes: plt.Axes, xticks: np.ndarray | None = None\n",
    ") -> plt.Axes:\n",
    "    xs = np.arange(1, 4096 + 1) if xticks is None else xticks\n",
    "    axes.plot(xs, state_measures_map[\"pre\"].mean(axis=0), label=\"Untrained\", ls=\":\")\n",
    "    axes.plot(xs, state_measures_map[\"post\"].mean(axis=0), label=\"Trained\", ls=\"-\")\n",
    "    axes.set_xscale(\"log\")\n",
    "    axes.set_ylim([0, 1.05])\n",
    "    axes.grid(True)\n",
    "    return axes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load measures from both experiments (N3P2, N4P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuplicateResultError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ResultConfig:\n",
    "    dataset: DataSet\n",
    "    noise: int\n",
    "    arch: str\n",
    "    state: str\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.dataset, self.noise, self.arch, self.state))\n",
    "\n",
    "    def __eq__(self, other: ResultConfig):\n",
    "        return (self.dataset, self.noise, self.arch, self.state) == (\n",
    "            other.dataset,\n",
    "            other.noise,\n",
    "            other.arch,\n",
    "            other.state,\n",
    "        )\n",
    "\n",
    "\n",
    "class ResultStore:\n",
    "    def __init__(self):\n",
    "        self.results: dict[ResultConfig, npt.NDArray[np.float_]] = {}\n",
    "\n",
    "    def add(self, config: ResultConfig, result: npt.NDArray[np.float_]):\n",
    "        if config in self.results:\n",
    "            raise DuplicateResultError(\n",
    "                f\"Result for configuration {config} already exists.\"\n",
    "            )\n",
    "        self.results[config] = result\n",
    "\n",
    "    def get(self, config: ResultConfig | dict) -> npt.NDArray[np.float_]:\n",
    "        if isinstance(config, dict):\n",
    "            _config = ResultConfig(**config)\n",
    "        return self.results[config]\n",
    "\n",
    "\n",
    "def push_results(\n",
    "    datastore: ResultStore, dataset: DataSet, noise: int, records: dict\n",
    ") -> None:\n",
    "    for arch, state in product([\"ALL\"], [\"pre\", \"post\"]):\n",
    "        cfg = ResultConfig(dataset=dataset, noise=noise, arch=arch, state=state)\n",
    "        datastore.add(cfg, records[arch][state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdirs = {\n",
    "    DataSet.N4P2: \"n4p2/train_n4p2_lrate_0_02_181023\",\n",
    "}\n",
    "amplitudes = [0, 10, 20]\n",
    "\n",
    "results_ds = ResultStore()\n",
    "for dataset, logdir in logdirs.items():\n",
    "    expt = handler.ExperimentHandler(logdir)\n",
    "    dataset_name = Path(logdir).parent.name\n",
    "    for noise in amplitudes:\n",
    "        results = load_measures(RESULTS_DIR / dataset_name, noise=noise)\n",
    "        push_results(results_ds, dataset, noise, results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1: Information analysis (noise)\n",
    "\n",
    "**Details:**\n",
    "\n",
    "- Target `ALL` architecture: the one most relevant to this study\n",
    "- Plot trend up to maximum noise when close to no neurons are selective before training\n",
    "\n",
    "**Layout:**\n",
    "\n",
    "- Cols: N3P2, N4P2\n",
    "- Rows: noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"ALL\"\n",
    "states = [\"pre\", \"post\"]\n",
    "\n",
    "measures_dict: dict[\n",
    "    DataSet, dict[int, dict[str, np.ndarray]]\n",
    "] = {}  # DataSet -> {noise -> {state -> array}}\n",
    "for dataset in [DataSet.N4P2]:\n",
    "    if dataset not in measures_dict:\n",
    "        measures_dict[dataset] = {}\n",
    "    for noise in amplitudes:\n",
    "        if noise not in measures_dict[dataset]:\n",
    "            measures_dict[dataset][noise] = {}\n",
    "        for state in states:\n",
    "            cfg = ResultConfig(dataset, noise, arch, state)\n",
    "            measures_dict[dataset][noise][state] = results_ds.get(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup image inset plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfg = {\n",
    "    \"name\": \"n4p2\",\n",
    "    \"transforms\": {\n",
    "        \"resize\": [[128, 128]],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def plot_image(\n",
    "    image: np.ndarray, show_ticks: bool = False, axes: plt.Axes | None = None\n",
    ") -> plt.Axes:\n",
    "    axes = viz.imshow_cbar(\n",
    "        image, attach_cbar=False, cmax=255, axes=axes, rasterized=True\n",
    "    )\n",
    "    if not show_ticks:\n",
    "        axes.set_xticks([])\n",
    "        axes.set_yticks([])\n",
    "    return axes\n",
    "\n",
    "\n",
    "def load_imageset(amplitude: int, cfg: dict) -> tuple[utils.ImageSet, pd.DataFrame]:\n",
    "    _cfg = deepcopy(cfg)\n",
    "    if amplitude > 0:\n",
    "        _cfg[\"transforms\"][\"gaussiannoise\"] = [amplitude]\n",
    "    return utils.io.get_dataset(_cfg, return_annotations=True)\n",
    "\n",
    "\n",
    "# Get target image at given noise levels\n",
    "img_id = 5\n",
    "images = {noise: load_imageset(noise, data_cfg)[0][img_id] for noise in amplitudes}\n",
    "\n",
    "noise = 20\n",
    "f, axes = plt.subplots(figsize=(2.5, 2.5))\n",
    "plot_image(images[noise], axes=axes)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Information plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet.N4P2\n",
    "\n",
    "overwrite = False\n",
    "width = 3.5\n",
    "height = 4\n",
    "\n",
    "f, axes = plt.subplots(3, 1, figsize=(width, height))\n",
    "for row, noise in enumerate(amplitudes):\n",
    "    ax: plt.Axes = axes[row]\n",
    "    state_measures_map = measures_dict[dataset][noise]\n",
    "    plot_grid(state_measures_map, ax)\n",
    "    # Inset image\n",
    "    inset_axes_ = inset_axes(\n",
    "        ax,\n",
    "        width=\"50%\",\n",
    "        height=\"50%\",\n",
    "        bbox_to_anchor=(0.33, 0.2, 1, 1),\n",
    "        bbox_transform=ax.transAxes,\n",
    "        loc=\"center\",\n",
    "    )\n",
    "    plot_image(images[noise], axes=inset_axes_)\n",
    "    # ticks, labels\n",
    "    # if row == 0:\n",
    "    #     ax.set_title(dataset.name, size=10, pad=10, fontweight='bold')\n",
    "    if row < 2:\n",
    "        ax.set_xticklabels([])\n",
    "    else:\n",
    "        ax.set_xlabel(\"Neuron rank #\")\n",
    "    ax.set_ylabel(r\"$\\mathcal{I}\\; (s, \\vec{R})$\")\n",
    "    ax.text(\n",
    "        -0.4,\n",
    "        0.5,\n",
    "        rf\"$\\sigma={noise}$\",\n",
    "        size=10,\n",
    "        horizontalalignment=\"right\",\n",
    "        verticalalignment=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    if ax == axes[0]:\n",
    "        ax.legend(fontsize=\"x-small\", loc=\"lower left\")\n",
    "    # ax.set_xlim([None, 1.5e3])\n",
    "    ax.set_xlim([1, 4096])\n",
    "f.tight_layout()\n",
    "fname = OUTPUT_DIR / \"fig_information_noise.pdf\"\n",
    "viz.save_figure(f, fname, overwrite=overwrite, dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2: number of most selective neurons (noise)\n",
    "\n",
    "**Styles:**\n",
    "\n",
    "- Bar chart: N4P2\n",
    "- Plot number of neurons with I(s, R) > 2/3 per noise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_num_selective(info_measures: np.ndarray, threshold: float = 2 / 3.0) -> int:\n",
    "    if info_measures.ndim == 2:\n",
    "        info_measures_ = info_measures.mean(0)\n",
    "    elif info_measures.ndim == 1:\n",
    "        info_measures_ = info_measures\n",
    "    else:\n",
    "        raise ValueError(info_measures.shape)\n",
    "    return (info_measures_ > threshold).sum()\n",
    "\n",
    "\n",
    "def get_num_selective_dataset(\n",
    "    measures_noise: dict[int, dict[str, np.ndarray]], threshold: float = 2 / 3.0\n",
    ") -> tuple[list[int], dict[str, list[int]]]:\n",
    "    values = {\"pre\": [], \"post\": []}\n",
    "    amplitudes = []\n",
    "    for amplitude, measures_state in measures_noise.items():\n",
    "        amplitudes.append(amplitude)\n",
    "        for state, info_measures in measures_state.items():\n",
    "            values[state].append(_get_num_selective(info_measures, threshold))\n",
    "    return amplitudes, values\n",
    "\n",
    "\n",
    "def plot_number_selective_neurons(\n",
    "    num_selective_nrns: dict[str, npt.ArrayLike],\n",
    "    dataset_name: str,\n",
    "    labels: list,\n",
    "    axes: plt.Axes | None = None,\n",
    ") -> plt.Axes:\n",
    "    axes = viz.base.setup_axes(axes)\n",
    "    axes.grid(axis=\"y\")\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    y1 = num_selective_nrns[\"pre\"]\n",
    "    y2 = num_selective_nrns[\"post\"]\n",
    "\n",
    "    # Width of a bar\n",
    "    width = 0.4\n",
    "    factor = 1 / 2 + 0.05\n",
    "\n",
    "    axes: plt.Axes\n",
    "    bars1 = axes.bar(x - width * factor, y1, width, label=\"Untrained\", zorder=3)\n",
    "    bars2 = axes.bar(x + width * factor, y2, width, label=\"Trained\", zorder=3)\n",
    "\n",
    "    # Add percentage labels above bars\n",
    "    num_total = 4096\n",
    "    for bar, val in zip(bars1, y1):\n",
    "        pct = val / num_total * 100\n",
    "        pct = val / num_total * 100\n",
    "        if pct > 0:\n",
    "            axes.annotate(\n",
    "                f\"{pct:.1f}%\",\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=\"x-small\",\n",
    "            )\n",
    "    for bar, val in zip(bars2, y2):\n",
    "        pct = val / num_total * 100\n",
    "        if pct > 0:\n",
    "            axes.annotate(\n",
    "                f\"{pct:.1f}%\",\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=\"x-small\",\n",
    "            )\n",
    "\n",
    "    # axes.set_title(f\"{dataset_name}\", fontweight='bold', fontsize=10)\n",
    "    axes.set_xticks(x)\n",
    "    axes.set_xticks(x, labels)\n",
    "    axes.set_xlabel(r\"Noise amplitude ($\\sigma$)\")\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2 / 3\n",
    "overwrite = False\n",
    "\n",
    "f, axes = plt.subplots(1, figsize=(2.5, 3), sharey=True)\n",
    "\n",
    "amplitudes, num_selective_nrns = get_num_selective_dataset(\n",
    "    measures_dict[dataset], threshold=threshold\n",
    ")\n",
    "ax = plot_number_selective_neurons(\n",
    "    num_selective_nrns, dataset.name, amplitudes, axes=axes\n",
    ")\n",
    "ax.set_ylabel(\"# informative neurons\")\n",
    "ax.legend()\n",
    "f.tight_layout()\n",
    "\n",
    "fname = OUTPUT_DIR / \"fig_informative_neurons_noise.pdf\"\n",
    "viz.save_figure(f, fname, overwrite=overwrite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
