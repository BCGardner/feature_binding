{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selectivity N4P2 (noise)\n",
    "\n",
    "Neuronal response properties before and after training with Gaussian noise applied to shapes from N4P2.\n",
    "\n",
    "**Dependencies:**\n",
    "\n",
    "- Inference spike recordings for N4P2: both before and after network training\n",
    "- Depends on N4P2 workflows (with and without the `--chkpt -1` argument):\n",
    "```bash\n",
    "./scripts/run_main_workflow.py experiments/n4p2/train_n4p2_lrate_0_02_181023 15 --rule inference --subdir noise --noise 20 -v\n",
    "```\n",
    "\n",
    "**Plots:**\n",
    "\n",
    "- Firing rate distributions (pre vs. post)\n",
    "- L4 Gabor traceback analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from hsnn import analysis, simulation, utils, viz\n",
    "from hsnn.cluster import tasks\n",
    "from hsnn.utils import handler, io\n",
    "from hsnn.utils.handler import TrialView\n",
    "from hsnn import transforms\n",
    "\n",
    "OUTPUT_DIR = io.BASE_DIR / \"out/figures/fig12\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_inference_results(\n",
    "    trial: TrialView, chkpt: int | None, **kwargs\n",
    ") -> xr.DataArray:\n",
    "    results_path = handler.get_results_path(trial, chkpt, **kwargs)\n",
    "    if results_path.is_file():\n",
    "        print(f\"Loading '{results_path}'...\")\n",
    "        return utils.io.load_pickle(results_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"'{results_path}'\")\n",
    "\n",
    "\n",
    "def load_imageset(amplitude: int, cfg: dict) -> tuple[utils.ImageSet, pd.DataFrame]:\n",
    "    _cfg = deepcopy(cfg)\n",
    "    if amplitude > 0:\n",
    "        _cfg[\"training\"][\"data\"][\"transforms\"][\"gaussiannoise\"] = [amplitude]\n",
    "    return utils.io.get_dataset(_cfg[\"training\"][\"data\"], return_annotations=True)\n",
    "\n",
    "\n",
    "class InferenceConfig(BaseModel):\n",
    "    \"\"\"Inference kwargs passed to `handler.load_results`.\"\"\"\n",
    "\n",
    "    noise: int\n",
    "    subdir: str | None = None\n",
    "\n",
    "\n",
    "records: dict[str, xr.DataArray] = {\"pre\": None, \"post\": None}\n",
    "syn_params: dict[str, pd.DataFrame] = {\"pre\": None, \"post\": None}\n",
    "state_chkpt_mapping = {\"pre\": None, \"post\": -1}\n",
    "\n",
    "viz.setup_journal_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load N4P2 recorded results\n",
    "\n",
    "**Get representative Trial for `ALL` architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"n4p2/train_n4p2_lrate_0_02_181023\"\n",
    "trial_index = (20, 20, 3)\n",
    "\n",
    "expt = handler.ExperimentHandler(logdir)\n",
    "print(f\"Experiment selected: '{expt.name}'\")\n",
    "dataset_name = expt.logdir.parent.stem\n",
    "\n",
    "trial = expt[trial_index]\n",
    "cfg = trial.config\n",
    "print(f\"Trial selected: '{trial.name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load pre / post-training results at highest noise amplitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 20\n",
    "subdir = \"noise\" if amplitude > 0 else None\n",
    "offset = 50.0\n",
    "inference_cfg = InferenceConfig(noise=amplitude, subdir=\"noise\")\n",
    "\n",
    "# Recordings per noise amplitude\n",
    "for state, chkpt in state_chkpt_mapping.items():\n",
    "    records[state] = load_inference_results(trial, chkpt, **dict(inference_cfg))\n",
    "\n",
    "# Common parameters\n",
    "duration: float = records[\"post\"].item(0).duration - offset  # Observation period\n",
    "reps = len(records[\"post\"][\"rep\"])\n",
    "input_shape = tuple(cfg[\"topology\"][\"poisson\"][\"EXC\"])\n",
    "layer_shape = tuple(cfg[\"topology\"][\"spatial\"][\"EXC\"])\n",
    "\n",
    "# Get synapse parameters\n",
    "sim = simulation.Simulator.from_config(cfg)\n",
    "for state in (\"pre\", \"post\"):\n",
    "    chkpt = state_chkpt_mapping[state]\n",
    "    store_path = trial.checkpoints[chkpt].store_path if isinstance(chkpt, int) else None\n",
    "    if store_path is not None:\n",
    "        sim.restore(store_path)\n",
    "    syn_params[state] = sim.network.get_syn_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Viz network dynamics\n",
    "\n",
    "**Firing rate distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson firing rates\n",
    "state = \"post\"\n",
    "\n",
    "rates = records[state].sel(img=0, rep=0, layer=0, nrn_cls=\"EXC\").item().rates[1]\n",
    "\n",
    "f, axes = plt.subplots(figsize=(4, 2))\n",
    "axes.hist(rates[rates > 0], bins=60, density=True)\n",
    "axes.set_xlabel(\"Firing rate (Hz)\")\n",
    "axes.set_ylabel(r\"$f\\;(r)$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firing rates distributions for an image, rep\n",
    "img = 0\n",
    "rep = 0\n",
    "state = \"post\"\n",
    "\n",
    "viz.hist_rates(\n",
    "    records[state].sel(img=img, rep=rep, layer=slice(1, None)),\n",
    "    bins=60,\n",
    "    xmax=[200, 300],\n",
    "    figsize=(6, 8),\n",
    "    yticks=False,\n",
    "    xlabel=\"Firing rate (Hz)\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topological firing activity\n",
    "img = 0\n",
    "rep = 0\n",
    "state = \"post\"\n",
    "\n",
    "axes = viz.topographic_rates(\n",
    "    records[state].sel(img=img, rep=rep, layer=slice(1, None)),\n",
    "    plot_ticks=False,\n",
    "    figsize=(4, 8),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Compute sensitivities for a select neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters\n",
    "layer = 4\n",
    "\n",
    "imageset, labels = load_imageset(amplitude, trial.config)\n",
    "\n",
    "f, axes = plt.subplots(figsize=(2, 2))\n",
    "axes.imshow(imageset[1], cmap=\"gray\", vmin=0, vmax=255);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get or compute sensitivities**\n",
    "\n",
    "Runtime: ~2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn_id = 2176\n",
    "\n",
    "cache_dir = OUTPUT_DIR / \".cache\"\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "filepath = (\n",
    "    cache_dir / f\"sensitivities_{dataset_name}_noise_{amplitude}_L4_{nrn_id}.pkl\"\n",
    ")\n",
    "sensitivities_dict: dict[str, pd.DataFrame] = {}  # state -> pd.DataFrame\n",
    "if not filepath.exists():\n",
    "    for state in tqdm([\"pre\", \"post\"]):\n",
    "        sensitivities_dict[state] = tasks.get_sensitivities(\n",
    "            nrn_id,\n",
    "            layer,\n",
    "            duration,\n",
    "            offset,\n",
    "            records[state],\n",
    "            syn_params[state],\n",
    "            input_shape,\n",
    "        )\n",
    "    io.save_pickle(sensitivities_dict, filepath)\n",
    "else:\n",
    "    sensitivities_dict: dict[str, pd.DataFrame] = io.load_pickle(filepath)\n",
    "    print(f\"Loaded cached sensitivities from '{filepath}'\")\n",
    "\n",
    "norm_maxes: dict[str, float] = {}  # amplitude -> max sensitivity\n",
    "for state, sensitivities_df in sensitivities_dict.items():\n",
    "    norm_maxes[state] = sensitivities_df.max(skipna=True).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Figure: Boundary contour element selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = [4]\n",
    "\n",
    "rate_arrays: dict[str, xr.DataArray] = {}\n",
    "for state in (\"pre\", \"post\"):\n",
    "    rate_arrays[state] = analysis.infer_rates(\n",
    "        records[state].sel(layer=layer, nrn_cls=\"EXC\"), duration, offset\n",
    "    )\n",
    "print(f\"Firing rates array: layer={layer}; duration={duration}; offset={offset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_selectivity_panel(\n",
    "    axes,\n",
    "    rates_array,\n",
    "    layer,\n",
    "    nrn_id,\n",
    "    labels,\n",
    "    yticks=None,\n",
    "    ylim=None,\n",
    "    title: str | None = None,\n",
    "):\n",
    "    viz.plot_contour_selectivity(\n",
    "        rates_array.sel(layer=layer),\n",
    "        nrn_id,\n",
    "        labels,\n",
    "        violinplot=False,\n",
    "        show_xlabels=True,\n",
    "        rotate_xticklabels=False,\n",
    "        axes=axes,\n",
    "    )\n",
    "    axes.set_title(title, fontweight=\"bold\")\n",
    "    _ylim = ylim if ylim is not None else [0, None]\n",
    "    axes.set_ylim(_ylim)\n",
    "    if yticks is not None:\n",
    "        axes.set_yticks(yticks)\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ = labels.copy()\n",
    "labels_ = labels_[[\"image_id\", \"left\"]]\n",
    "\n",
    "width = 2  # * 1.125\n",
    "height = 3.5\n",
    "\n",
    "yticks = range(0, 50, 20)\n",
    "ylim = [0, 45]\n",
    "\n",
    "f, axes = plt.subplots(2, 1, figsize=(width, height), sharex=True, sharey=True)\n",
    "ax = plot_selectivity_panel(\n",
    "    axes[0],\n",
    "    rate_arrays[\"pre\"],\n",
    "    layer=4,\n",
    "    nrn_id=nrn_id,\n",
    "    labels=labels_,\n",
    "    yticks=yticks,\n",
    "    ylim=ylim,\n",
    "    title=\"Untrained\",\n",
    ")\n",
    "ax = plot_selectivity_panel(\n",
    "    axes[1],\n",
    "    rate_arrays[\"post\"],\n",
    "    layer=4,\n",
    "    nrn_id=nrn_id,\n",
    "    labels=labels_,\n",
    "    yticks=yticks,\n",
    "    ylim=ylim,\n",
    "    title=\"Trained\",\n",
    ")\n",
    "\n",
    "\n",
    "def map_xlabel(xlabel):\n",
    "    text = \" /\\n\".join(xlabel.get_text().split(\": \"))\n",
    "    xlabel.set_text(text)\n",
    "    # xlabel.set_horizontalalignment('left')\n",
    "    return xlabel\n",
    "\n",
    "\n",
    "ax: plt.Axes = axes[-1]\n",
    "xlabels = [map_xlabel(lab) for lab in ax.get_xticklabels()]\n",
    "xticklabels = ax.set_xticklabels(xlabels)\n",
    "f.tight_layout()\n",
    "f.subplots_adjust(hspace=0.4)\n",
    "\n",
    "f.savefig(OUTPUT_DIR / 'fig_neuron_rates.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Firing rate statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ids = np.flatnonzero(labels[\"left\"] == 1)\n",
    "neg_ids = np.flatnonzero(labels[\"left\"] == 0)\n",
    "pos_ids, neg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = \"post\"\n",
    "\n",
    "rates_neg = rate_arrays[state].sel(img=neg_ids, nrn=nrn_id, layer=4).values.ravel()\n",
    "rates_pos = rate_arrays[state].sel(img=pos_ids, nrn=nrn_id, layer=4).values.ravel()\n",
    "rates = np.vstack([rates_neg, rates_pos])\n",
    "print(f\"Negative rates: {rates_neg.mean():.1f} ({rates_neg.std():.1f}) Hz\")\n",
    "print(f\"Positive rates: {rates_pos.mean():.1f} ({rates_pos.std():.1f}) Hz\")\n",
    "\n",
    "plt.violinplot(rates.T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Figure: traceback\n",
    "\n",
    "Select L4 neuron traceback\n",
    "\n",
    "Details:\n",
    "- Left: Negative image\n",
    "- Middle: Positive image\n",
    "- Right: Averaged response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Gaussian distorted background\n",
    "tsf = transforms.GaussianNoise(amplitude)\n",
    "image_bg = np.full(input_shape[1:], 128.0)\n",
    "\n",
    "\n",
    "def subplot_traceback(axes, img, sensitivities_df, norm_max, sel_kwargs=None):\n",
    "    _sel_kwargs = sel_kwargs or {\"s\": 5, \"linewidths\": 0}\n",
    "    if img is None:\n",
    "        sensitivities = sensitivities_df.mean(axis=1, skipna=True)\n",
    "        image = tsf.transform(image_bg)\n",
    "    else:\n",
    "        sensitivities = sensitivities_df[img].dropna()\n",
    "        image = imageset[img]\n",
    "\n",
    "    viz.plot_traceback(\n",
    "        sensitivities,\n",
    "        image,\n",
    "        nrn_id=None,\n",
    "        layer_shape=layer_shape,\n",
    "        sensitivities_max=norm_max,\n",
    "        vmin=0,\n",
    "        vmax=255,\n",
    "        color=\"red\",\n",
    "        sel_kwargs=_sel_kwargs,\n",
    "        axes=axes,\n",
    "    )\n",
    "\n",
    "\n",
    "img_pos = 1\n",
    "img_neg = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Subplot A**\n",
    "\n",
    "State: `Pre`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "state = \"pre\"\n",
    "\n",
    "np.random.seed(seed)\n",
    "sensitivities = sensitivities_dict[state]\n",
    "norm_max = norm_maxes[state]\n",
    "\n",
    "width = 1.2\n",
    "# width = 3.2\n",
    "sel_kwargs = {\"s\": 5, \"linewidths\": 0}\n",
    "# sel_kwargs = {'s': 30, 'linewidths': 0}\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(3 * width, width))\n",
    "\n",
    "# Plot negative case\n",
    "ax: plt.Axes = axes[0]\n",
    "subplot_traceback(ax, img_neg, sensitivities, norm_maxes[state], sel_kwargs=sel_kwargs)\n",
    "# ax.set_title('Derp', fontweight='bold')\n",
    "# Plot negative case\n",
    "ax: plt.Axes = axes[1]\n",
    "subplot_traceback(ax, img_pos, sensitivities, norm_maxes[state], sel_kwargs=sel_kwargs)\n",
    "# Plot negative case\n",
    "ax: plt.Axes = axes[2]\n",
    "subplot_traceback(ax, None, sensitivities, norm_maxes[state], sel_kwargs=sel_kwargs)\n",
    "\n",
    "f = plt.gcf()\n",
    "f.tight_layout()\n",
    "\n",
    "f.savefig(OUTPUT_DIR / f'fig_traceback_untrained_L4_{nrn_id}.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subplot B**\n",
    "\n",
    "State: `Post`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 43\n",
    "state = \"post\"\n",
    "\n",
    "np.random.seed(seed)\n",
    "sensitivities = sensitivities_dict[state]\n",
    "norm_max = norm_maxes[state]\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(3 * width, width))\n",
    "\n",
    "# Plot negative case\n",
    "ax: plt.Axes = axes[0]\n",
    "subplot_traceback(ax, img_neg, sensitivities, norm_maxes[state], sel_kwargs=sel_kwargs)\n",
    "# ax.set_title('Derp', fontweight='bold')\n",
    "# Plot negative case\n",
    "ax: plt.Axes = axes[1]\n",
    "subplot_traceback(ax, img_pos, sensitivities, norm_maxes[state], sel_kwargs=sel_kwargs)\n",
    "# Plot negative case\n",
    "ax: plt.Axes = axes[2]\n",
    "subplot_traceback(ax, None, sensitivities, norm_maxes[state], sel_kwargs=sel_kwargs)\n",
    "\n",
    "f = plt.gcf()\n",
    "f.tight_layout()\n",
    "\n",
    "f.savefig(OUTPUT_DIR / f'fig_traceback_trained_L4_{nrn_id}.pdf', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
