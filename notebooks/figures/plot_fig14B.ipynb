{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot HFB Performance metrics\n",
    "\n",
    "Quantify the performance of HFBs in terms of their ability to classify convex (or concave) boundary elements.\n",
    "\n",
    "**Methods**\n",
    "\n",
    "- Using both experiments (datasets) and averaging over three trials of PNG detections.\n",
    "- Plot F1-scores for each dataset:\n",
    "    - Depicts the performance for (FF + LAT) network architecture, and (FF + LAT + FB).\n",
    "    - Each curve is the aggregate across all convex (or concave) boundaries, and then averaged across three select Trials.\n",
    "    - The error curve corresponds to the standard deviation across these three Trials.\n",
    "- F1-score is the harmonic mean of the Precision and Recall.\n",
    "\n",
    "**Dependencies:**\n",
    "\n",
    "---\n",
    "\n",
    "A) Significance testing:\n",
    "- PNG detection and significance testing for N3P2 & N4P2: both before and after network training\n",
    "---\n",
    "\n",
    "B) Compute PNG F1 scores:\n",
    "\n",
    "- Also run these with the argument `--target 0` for concave selectivity.\n",
    "\n",
    "i) For N3P2:\n",
    "```bash\n",
    "for arch in SEMI ALL; do\n",
    "    ./scripts/figures/compute_png_metrics.py ./experiments/n3p2/train_n3p2_lrate_0_04_181023 $arch -v\n",
    "done\n",
    "```\n",
    "ii) and N4P2:\n",
    "```bash\n",
    "for arch in SEMI ALL; do\n",
    "    ./scripts/figures/compute_png_metrics.py ./experiments/n4p2/train_n4p2_lrate_0_02_181023 $arch -v\n",
    "done\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Results**\n",
    "\n",
    "- Despite intricate nature of a three-neuron HFB circuit, observe substantial number selective ones.\n",
    "- Compare metrics across datasets.\n",
    "- Compare metrics across network archs. (FF + LAT) vs (FF + LAT + FB).\n",
    "\n",
    "**Plots**\n",
    "\n",
    "- Fig 14B (convex)\n",
    "- Supplementary Fig S6 (concave)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hsnn import viz\n",
    "from hsnn.utils import io\n",
    "\n",
    "pidx = pd.IndexSlice\n",
    "OUTPUT_DIR = io.BASE_DIR / \"out/figures/fig14\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR = io.BASE_DIR / \"out/figures/detection\"\n",
    "ARCH_DESC_MAPPING = {\"FF\": \"FF\", \"SEMI\": \"FF+LAT\", \"ALL\": \"FF+LAT+FB\"}\n",
    "\n",
    "\n",
    "class DataSet(Enum):\n",
    "    N3P2 = 1\n",
    "    N4P2 = 2\n",
    "\n",
    "\n",
    "def plot_scores(scores: pd.DataFrame, dataset_name: str, ax: plt.Axes):\n",
    "    scores_avs = {}\n",
    "    scores_errs = {}\n",
    "    for col_name in scores.columns.unique(0):\n",
    "        scores_avs[col_name] = scores[col_name].mean(axis=1).values\n",
    "        scores_errs[col_name] = scores[col_name].std(axis=1).values\n",
    "\n",
    "    for idx, col_name in enumerate(scores_avs.keys()):\n",
    "        scores_av = scores_avs[col_name]\n",
    "        scores_err = scores_errs[col_name]\n",
    "        xticks = np.arange(1, len(scores_av) + 1)\n",
    "        ax.fill_between(\n",
    "            xticks,\n",
    "            scores_av - scores_err,\n",
    "            scores_av + scores_err,\n",
    "            color=colors[idx],\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        ax.plot(\n",
    "            xticks,\n",
    "            scores_av,\n",
    "            color=colors[idx],\n",
    "            linestyle=\"-\",\n",
    "            label=ARCH_DESC_MAPPING[col_name],\n",
    "        )\n",
    "        ax.grid(color=\"lightgray\")\n",
    "\n",
    "\n",
    "logdirs = {DataSet.N3P2: \"n3p2\", DataSet.N4P2: \"n4p2\"}\n",
    "\n",
    "# Plotting\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "colors = prop_cycle.by_key()[\"color\"]\n",
    "\n",
    "viz.setup_journal_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load performance metrics\n",
    "- Precision and recall determined per PNG.\n",
    "- This is used to plot the PNG F1 score as a rank-order plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"convex\"  # \"convex\" or \"concave\"\n",
    "\n",
    "scores_datasets = {}\n",
    "for dataset, logdir in logdirs.items():\n",
    "    fpath = RESULTS_DIR / logdir / f\"png_f1_max_{target}.pkl\"\n",
    "    scores_datasets[dataset] = io.load_pickle(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Plot scores for each model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "width = 5.5\n",
    "height = 2.5\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(width, height), sharex=True, sharey=True)\n",
    "\n",
    "for idx, (ds, scores_ds) in enumerate(scores_datasets.items()):\n",
    "    png_f1_scores = pd.concat(\n",
    "        {k: pd.DataFrame(v.T) for k, v in scores_datasets[ds].items()}, axis=1\n",
    "    )\n",
    "    ax = axes[idx]\n",
    "    plot_scores(png_f1_scores, ds.name, ax=ax)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"PNG rank #\")\n",
    "    ax.set_xlim([1, 1e4])\n",
    "    ax.set_title(ds.name.upper(), pad=10, fontweight=\"bold\")\n",
    "axes[0].legend(loc=\"lower left\", frameon=True, framealpha=1)\n",
    "axes[0].set_ylabel(\"F1 score\")\n",
    "axes[0].set_ylim([0, 1.05])\n",
    "f.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "filedir = OUTPUT_DIR / f\"fig_png_f1_{target}_datasets.pdf\"\n",
    "if overwrite or not filedir.exists():\n",
    "    f.savefig(filedir, format=\"pdf\", dpi=300)\n",
    "    print(f\"Saved figure to '{filedir}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Summary Statistics\n",
    "Compute key statistical summaries including the number of PNGs with high F1 scores (> 0.9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics for each dataset and architecture\n",
    "f1_threshold = 0.9\n",
    "\n",
    "summary_data = []\n",
    "for ds, scores_ds in scores_datasets.items():\n",
    "    png_f1_scores = pd.concat(\n",
    "        {k: pd.DataFrame(v.T) for k, v in scores_ds.items()}, axis=1\n",
    "    )\n",
    "\n",
    "    for arch in png_f1_scores.columns.unique(0):\n",
    "        arch_scores = png_f1_scores[arch]\n",
    "        # Average across trials for each PNG\n",
    "        mean_scores = arch_scores.mean(axis=1)\n",
    "\n",
    "        n_pngs = len(mean_scores)\n",
    "        n_high_f1 = (mean_scores > f1_threshold).sum()\n",
    "        pct_high_f1 = 100 * n_high_f1 / n_pngs\n",
    "\n",
    "        summary_data.append({\n",
    "            \"Dataset\": ds.name,\n",
    "            \"Architecture\": ARCH_DESC_MAPPING[arch],\n",
    "            \"Total PNGs\": n_pngs,\n",
    "            f\"PNGs with F1 > {f1_threshold}\": n_high_f1,\n",
    "            f\"% PNGs with F1 > {f1_threshold}\": f\"{pct_high_f1:.1f}%\",\n",
    "            \"Mean F1\": f\"{mean_scores.mean():.3f}\",\n",
    "            \"Median F1\": f\"{mean_scores.median():.3f}\",\n",
    "            \"Max F1\": f\"{mean_scores.max():.3f}\",\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(f\"Summary Statistics (F1 threshold = {f1_threshold})\")\n",
    "print(\"=\" * 80)\n",
    "display(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
