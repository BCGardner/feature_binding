{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot HFB rasters\n",
    "\n",
    "Spike rasters of neuronal activity involved in three PNGs that structurally conform to three-neuron HFB circuits.\n",
    "\n",
    "**Dependencies:**\n",
    "\n",
    "Significance testing:\n",
    "- PNG detection and significance testing for N3P2: after network training\n",
    "- **This workflow is time-consuming to run**\n",
    "- Note that recorded spike trains and significance-tested PNGs are non-deterministic: **results may differ from manuscript**\n",
    "```bash\n",
    "./scripts/run_main_workflow.py experiments/n3p2/train_n3p2_lrate_0_04_181023 31 --chkpt -1 --rule significance -v\n",
    "```\n",
    "\n",
    "**Plots:**\n",
    "\n",
    "Spike rasters for three PNGs that are selective to left- right- and top-convex feature elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import hsnn.analysis.png.db as polydb\n",
    "from hsnn import utils, viz\n",
    "from hsnn.analysis.png import postproc, stats, PNG\n",
    "from hsnn.utils import handler, io\n",
    "\n",
    "pidx = pd.IndexSlice\n",
    "OUTPUT_DIR = io.BASE_DIR / \"out/figures/fig15\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_max_rep(polygrp: PNG, img: int) -> int:\n",
    "    mask = polygrp.imgs == img\n",
    "    rep_ids, counts = np.unique(polygrp.reps[mask], return_counts=True)\n",
    "    return rep_ids[np.argmax(counts)]\n",
    "\n",
    "\n",
    "# Plotting\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "colors = prop_cycle.by_key()[\"color\"]\n",
    "\n",
    "viz.setup_journal_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Select experiment\n",
    "\n",
    "Load representative trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"n3p2/train_n3p2_lrate_0_04_181023\"\n",
    "\n",
    "expt = handler.ExperimentHandler(logdir)\n",
    "dataset_name = Path(logdir).parent.name\n",
    "print(f\"Target dataset: {dataset_name}\")\n",
    "# Get relevant, representative Trials\n",
    "df = expt.get_summary(-1)\n",
    "closest_trials = expt.index_to_dir[handler.get_closest_samples(df)]\n",
    "closest_trials.drop([(0, 0), (0, 20), (20, 0)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load data\n",
    "\n",
    "Including Trial, spike records, HFB DB, detected PNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_id = \"TrainSNN_eb0d4_00031\"\n",
    "state = \"post\"\n",
    "offset = 50.0\n",
    "num_reps = 10\n",
    "\n",
    "# Get representative Trial\n",
    "trial = expt[trial_id]\n",
    "print(trial)\n",
    "\n",
    "# Get relevant spike records\n",
    "result = handler.load_results(trial, state)[state].sel(rep=range(num_reps))\n",
    "duration = result.item(0).duration - offset\n",
    "assert len(result.rep) == 10\n",
    "print(f\"\\nduration={duration}; offset={offset}; num_reps={num_reps}\")\n",
    "\n",
    "# Load imageset and labels\n",
    "imageset, labels = utils.io.get_dataset(\n",
    "    trial.config[\"training\"][\"data\"], return_annotations=True\n",
    ")\n",
    "\n",
    "# Get relevant HFB database\n",
    "database = handler.load_detections(trial, state)[state]\n",
    "\n",
    "# Get detected PNGs\n",
    "polygrps = polydb.get_polygrps(database)\n",
    "print(f\"Loading HFBs from '{database.path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Get F1 Scores\n",
    "\n",
    "To identify which HFBs to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance metrics per side\n",
    "occ_array = stats.get_occurrences_array(\n",
    "    polygrps, num_reps, len(imageset), index=1, duration=duration, offset=offset\n",
    ")\n",
    "metrics_side = stats.get_metrics_side(occ_array, labels, target=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) PNG raster plots (three examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select three top-most performant PNGs (left-convex, right-convex, top-convex)\n",
    "side_polygrp_id_mapping: dict[str, int] = {}\n",
    "for side in metrics_side.keys():\n",
    "    side_polygrp_id_mapping[side] = metrics_side[side].sort_values(\"score\", ascending=False).index[0]\n",
    "side_polygrp_id_mapping\n",
    "\n",
    "# (Alternatively) select by known indices\n",
    "# side_indices_mapping = {\n",
    "#     \"left\": [(3, 2889), (4, 1990), (4, 1927)],\n",
    "#     \"right\": [(3, 2623), (4, 2802), (4, 2737)],\n",
    "#     \"top\": [(3, 1129), (4, 1526), (4, 1591)],\n",
    "# }\n",
    "# side_polygrp_id_mapping = {\n",
    "#     side: polydb.find_matching_index(indices, polygrps) for side, indices in side_indices_mapping.items()\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report F1 score of the left- right- and top-convex selective PNGs\n",
    "for side, polygrp_id in side_polygrp_id_mapping.items():\n",
    "    f1_score = metrics_side[side].loc[polygrp_id][\"score\"]\n",
    "    print(f\"{side.capitalize()}-selective PNG (ID: {polygrp_id}): F1-score = {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trains_plotting(\n",
    "    polygrp: PNG,\n",
    "    imgs: list[int],\n",
    "    reps: list[int],\n",
    "    result: xr.DataArray,\n",
    "    offset: float,\n",
    ") -> tuple[dict, dict]:\n",
    "    \"\"\"Get spike trains for each (image, rep): entire sequences and PNG-specific ones\"\"\"\n",
    "    spike_trains_dict = {}\n",
    "    polygrp_trains_dict = {}\n",
    "\n",
    "    interval = 100\n",
    "    for key, img, rep in zip([\"null\", \"pos\"], imgs, reps):\n",
    "        spike_trains_dict[key] = postproc.get_spike_trains(\n",
    "            polygrp, img, rep, result, interval, offset, relative_times=True\n",
    "        )\n",
    "        polygrp_trains_dict[key] = postproc.get_polygrp_trains(\n",
    "            polygrp, img, rep, result, interval, offset, relative_times=True\n",
    "        )\n",
    "    # Concatenate the spike trains, null -> pos\n",
    "    spike_trains = postproc.concat_spike_trains(\n",
    "        spike_trains_dict[\"null\"], spike_trains_dict[\"pos\"], interval\n",
    "    )\n",
    "    polygrp_trains = postproc.concat_spike_trains(\n",
    "        polygrp_trains_dict[\"null\"], polygrp_trains_dict[\"pos\"], interval\n",
    "    )\n",
    "    return spike_trains, polygrp_trains\n",
    "\n",
    "\n",
    "def get_img_rep_ids(\n",
    "    polygrp, side: str, labels: pd.DataFrame\n",
    ") -> tuple[list[int], list[int]]:\n",
    "    \"\"\"Get list of images, reps, corresponding to null, positive cases.\"\"\"\n",
    "    img_null = (labels.drop(\"image_id\", axis=1).sum(axis=1) == 0).idxmax()\n",
    "    img_pos = (\n",
    "        (labels.drop(\"image_id\", axis=1).sum(axis=1) == 1) & labels[side] == 1\n",
    "    ).idxmax()\n",
    "\n",
    "    assert len(polygrp.reps[(polygrp.imgs == img_null)]) == 0, (\n",
    "        \"Prefer no spiking for null image\"\n",
    "    )\n",
    "    rep_null = 0\n",
    "    rep_pos = get_max_rep(polygrp, img_pos)\n",
    "    return ([img_null, img_pos], [rep_null, rep_pos])\n",
    "\n",
    "\n",
    "def plot_raster_row(\n",
    "    spike_trains: dict,\n",
    "    polygrp_trains: dict,\n",
    "    polygrp: PNG,\n",
    "    ax: plt.Axes,\n",
    "    xwidth: float,\n",
    "    xmin: float,\n",
    "    xlabel: str = \"\",\n",
    "    interval: float = 100,\n",
    "    **plot_kwargs,\n",
    "):\n",
    "    viz.plot_raster(\n",
    "        spike_trains,\n",
    "        xwidth,\n",
    "        xmin,\n",
    "        alpha=1,\n",
    "        axes=ax,\n",
    "        markerfacecolor=\"none\",\n",
    "        color=\"gray\",\n",
    "        xlabel=\"\",\n",
    "        **plot_kwargs,\n",
    "    )\n",
    "    viz.plot_raster(\n",
    "        polygrp_trains,\n",
    "        xwidth,\n",
    "        xmin,\n",
    "        alpha=1,\n",
    "        xlabel=xlabel,\n",
    "        axes=ax,\n",
    "        markerfacecolor=\"black\",\n",
    "        **plot_kwargs,\n",
    "    )\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.vlines([interval], ymin, ymax, colors=\"k\", linestyles=\"dashed\")\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    ax.set_yticks([0, 1, 2])\n",
    "    ax.set_yticklabels([f\"L{x[0]} #{x[1]}\" for x in zip(polygrp.layers, polygrp.nrns)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spike trains for the top- left- and right-selective PNGs\n",
    "spike_trains_side = {}\n",
    "polygrp_trains_side = {}\n",
    "polygrp_side = {}\n",
    "sides = []\n",
    "for side, png_id in side_polygrp_id_mapping.items():\n",
    "    polygrp = polygrps[png_id]\n",
    "    imgs, reps = get_img_rep_ids(polygrp, side, labels)\n",
    "    spike_trains_side[side], polygrp_trains_side[side] = get_trains_plotting(\n",
    "        polygrp, imgs, reps, result, offset\n",
    "    )\n",
    "    polygrp_side[side] = polygrp\n",
    "    sides.append(side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the concatenated spike trains: entire sequences and PNG-specific ones\n",
    "interval = 100\n",
    "width = 6\n",
    "height = 4.5\n",
    "\n",
    "xmin = 0\n",
    "xwidth = 2 * interval\n",
    "plot_kwargs = {\"markeredgewidth\": 2 / 3, \"marker\": \"o\", \"markersize\": 3}\n",
    "\n",
    "f, axes = plt.subplots(3, 1, figsize=(width, height), sharex=False)\n",
    "for i, side in enumerate(sides):\n",
    "    xlabel = \"\" if i < 2 else \"Time [ms]\"\n",
    "    plot_raster_row(\n",
    "        spike_trains_side[side],\n",
    "        polygrp_trains_side[side],\n",
    "        polygrp_side[side],\n",
    "        axes[i],\n",
    "        xwidth,\n",
    "        xmin,\n",
    "        xlabel=xlabel,\n",
    "        interval=interval,\n",
    "        **plot_kwargs,\n",
    "    )\n",
    "    axes[i].set_xticks(np.arange(xmin, xwidth + 50, 50))\n",
    "f.tight_layout()\n",
    "viz.save_figure(f, OUTPUT_DIR / \"fig15_png_rasters.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
