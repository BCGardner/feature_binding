{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot feature sharing across multiple HFBs\n",
    "\n",
    "Spike rasters of neuronal activity involved in two PNGs.\n",
    "\n",
    "**Dependencies:**\n",
    "\n",
    "Significance testing:\n",
    "- PNG detection and significance testing for N4P2: after network training\n",
    "- **This workflow is time-consuming to run**\n",
    "- Note that recorded spike trains and significance-tested PNGs are non-deterministic: **results may differ from manuscript**\n",
    "```bash\n",
    "./scripts/run_main_workflow.py experiments/n4p2/train_n4p2_lrate_0_02_181023 15 --chkpt -1 --rule significance -v\n",
    "```\n",
    "\n",
    "**Plots:**\n",
    "\n",
    "Spike rasters for two PNGs that are selective for a left-convex feature element, and which share the same high-level feature neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import hsnn.analysis.png.db as polydb\n",
    "from hsnn import ops, utils, viz\n",
    "from hsnn.analysis.png import postproc, refinery, stats, PNG\n",
    "from hsnn.utils import handler, io\n",
    "\n",
    "pidx = pd.IndexSlice\n",
    "OUTPUT_DIR = io.BASE_DIR / \"out/figures/fig17\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_max_rep(polygrp: PNG, img: int) -> int:\n",
    "    mask = polygrp.imgs == img\n",
    "    rep_ids, counts = np.unique(polygrp.reps[mask], return_counts=True)\n",
    "    return rep_ids[np.argmax(counts)]\n",
    "\n",
    "\n",
    "# Plotting\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "colors = prop_cycle.by_key()[\"color\"]\n",
    "\n",
    "viz.setup_journal_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Select experiment\n",
    "\n",
    "Load representative trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'n4p2/train_n4p2_lrate_0_02_181023'\n",
    "\n",
    "expt = handler.ExperimentHandler(logdir)\n",
    "dataset_name = Path(logdir).parent.name\n",
    "print(f\"Target dataset: {dataset_name}\")\n",
    "# Get relevant, representative Trials\n",
    "df = expt.get_summary(-1)\n",
    "closest_trials = expt.index_to_dir[handler.get_closest_samples(df)]\n",
    "closest_trials.drop([(0, 0), (0, 20), (20, 0)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load data\n",
    "\n",
    "Including Trial, spike records, HFB DB, detected PNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_id = \"TrainSNN_1fdbf_00015\"\n",
    "state = \"post\"\n",
    "offset = 50.0\n",
    "num_reps = 10\n",
    "\n",
    "# Get representative Trial\n",
    "trial = expt[trial_id]\n",
    "print(trial)\n",
    "\n",
    "# Get relevant spike records\n",
    "result = handler.load_results(trial, state)[state].sel(rep=range(num_reps))\n",
    "duration = result.item(0).duration - offset\n",
    "assert len(result.rep) == 10\n",
    "print(f\"\\nduration={duration}; offset={offset}; num_reps={num_reps}\")\n",
    "\n",
    "# Load imageset and labels\n",
    "imageset, labels = utils.io.get_dataset(\n",
    "    trial.config[\"training\"][\"data\"], return_annotations=True\n",
    ")\n",
    "\n",
    "# Get relevant HFB database\n",
    "database = handler.load_detections(trial, state)[state]\n",
    "\n",
    "# Get detected PNGs\n",
    "polygrps = polydb.get_polygrps(database)\n",
    "print(f\"Loaded HFBs from '{Path(database.path).relative_to(expt.logdir)}': {len(polygrps)} PNGs detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Get F1 Scores\n",
    "\n",
    "To identify which HFBs to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance metrics per side\n",
    "occ_array = stats.get_occurrences_array(\n",
    "    polygrps, num_reps, len(imageset), index=1, duration=duration, offset=offset\n",
    ")\n",
    "metrics_side = stats.get_metrics_side(occ_array, labels, target=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) PNG raster plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trains_plotting(\n",
    "    polygrp: PNG,\n",
    "    imgs: list[int],\n",
    "    reps: list[int],\n",
    "    result: xr.DataArray,\n",
    "    offset: float,\n",
    ") -> tuple[dict, dict]:\n",
    "    \"\"\"Get spike trains for each (image, rep): entire sequences and PNG-specific ones\"\"\"\n",
    "    spike_trains_dict = {}\n",
    "    polygrp_trains_dict = {}\n",
    "\n",
    "    interval = 100\n",
    "    for key, img, rep in zip([\"null\", \"pos\"], imgs, reps):\n",
    "        spike_trains_dict[key] = postproc.get_spike_trains(\n",
    "            polygrp, img, rep, result, interval, offset, relative_times=True\n",
    "        )\n",
    "        polygrp_trains_dict[key] = postproc.get_polygrp_trains(\n",
    "            polygrp, img, rep, result, interval, offset, relative_times=True\n",
    "        )\n",
    "    # Concatenate the spike trains, null -> pos\n",
    "    spike_trains = postproc.concat_spike_trains(\n",
    "        spike_trains_dict[\"null\"], spike_trains_dict[\"pos\"], interval\n",
    "    )\n",
    "    polygrp_trains = postproc.concat_spike_trains(\n",
    "        polygrp_trains_dict[\"null\"], polygrp_trains_dict[\"pos\"], interval\n",
    "    )\n",
    "    return spike_trains, polygrp_trains\n",
    "\n",
    "\n",
    "def get_img_rep_ids(\n",
    "    polygrp, side: str, labels: pd.DataFrame\n",
    ") -> tuple[list[int], list[int]]:\n",
    "    \"\"\"Get list of images, reps, corresponding to null, positive cases.\"\"\"\n",
    "    img_null = (labels.drop(\"image_id\", axis=1).sum(axis=1) == 0).idxmax()\n",
    "    img_pos = (\n",
    "        (labels.drop(\"image_id\", axis=1).sum(axis=1) == 1) & labels[side] == 1\n",
    "    ).idxmax()\n",
    "\n",
    "    assert len(polygrp.reps[(polygrp.imgs == img_null)]) == 0, (\n",
    "        \"Prefer no spiking for null image\"\n",
    "    )\n",
    "    rep_null = 0\n",
    "    rep_pos = get_max_rep(polygrp, img_pos)\n",
    "    return ([img_null, img_pos], [rep_null, rep_pos])\n",
    "\n",
    "\n",
    "def plot_raster_row(spike_trains: dict, polygrp_trains: dict, polygrp: PNG,\n",
    "                    ax: plt.Axes, xwidth: float, xmin: float, xlabel: str = '', **plot_kwargs):\n",
    "    viz.plot_raster(spike_trains, xwidth, xmin, alpha=1, axes=ax,\n",
    "                    markerfacecolor='none', color='gray', xlabel='', **plot_kwargs)\n",
    "    viz.plot_raster(polygrp_trains, xwidth, xmin, alpha=1, xlabel=xlabel, axes=ax,\n",
    "                    markerfacecolor='black', **plot_kwargs)\n",
    "    ax.set_yticks([0, 1, 2])\n",
    "    ax.set_yticklabels([f'L{x[0]} #{x[1]}' for x in zip(polygrp.layers, polygrp.nrns)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Plot HFB combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aligned_polygrps(query: PNG, position: int, database, tol: float = 3.0) -> list[PNG]:\n",
    "    target_times = [float(t) for t in query.lags[position] + query.times]\n",
    "    polygrps_aligned = polydb.query_aligned_pngs(\n",
    "        int(query.nrns[position]), int(query.layers[position]),\n",
    "        position, target_times, database, tol\n",
    "    )\n",
    "    return polygrps_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PNGs temporally-aligned with query neuron\n",
    "refine = refinery.FilterIndex((4, 2176), position=1)\n",
    "\n",
    "try:\n",
    "    polygrp_sel = refine(polygrps)[0]\n",
    "except IndexError:\n",
    "    raise UserWarning(\"No PNGs found for the given query - select a different query PNG\")\n",
    "\n",
    "# Get all PNGs with timing(s) that are aligned with a focal neuron in a query PNG\n",
    "polygrps_aligned = get_aligned_polygrps(polygrp_sel, 1, database)\n",
    "if not len(polygrps_aligned) > 1:\n",
    "    raise UserWarning(\"No aligned PNGs found for the given query - select a different query PNG\")\n",
    "\n",
    "# Select first two temporally-aligned PNGs\n",
    "polygrps_sel = polygrps_aligned[:2]\n",
    "polygrps_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique [(img, rep), ...] where there are one or more coincident activations\n",
    "high1_onsets = polygrps_sel[0].times + polygrps_sel[0].lags[1]\n",
    "high2_onsets = polygrps_sel[1].times + polygrps_sel[1].lags[1]\n",
    "coincidence_mask = np.isclose(np.abs(high1_onsets.reshape(-1, 1) - high2_onsets).min(axis=1), 0)\n",
    "eligible_idxs = np.flatnonzero(coincidence_mask)\n",
    "if len(eligible_idxs) == 0:\n",
    "    raise UserWarning(\"No coincident activations found between the two PNGs - select different PNGs.\")\n",
    "\n",
    "imgs_reps_coincident = sorted(set(zip(polygrps_sel[0].imgs[eligible_idxs], polygrps_sel[0].reps[eligible_idxs])))\n",
    "imgs_reps_coincident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spike patterns, activation patterns, for select PNGs on (img, rep)\n",
    "img_id, rep_id = imgs_reps_coincident[0]\n",
    "# img_id, rep_id = 7, 9\n",
    "print(f\"Selected (img, rep) for plotting: ({img_id}, {rep_id})\")\n",
    "\n",
    "spike_patterns = {}\n",
    "for i, polygrp in enumerate(polygrps_sel):\n",
    "    spike_patterns[i] = postproc.get_spike_trains(\n",
    "        polygrp, img_id, rep_id, result, duration, offset, True\n",
    "    )\n",
    "\n",
    "polygrp_patterns = {}\n",
    "for i, polygrp in enumerate(polygrps_sel):\n",
    "    polygrp_patterns[i] = postproc.get_polygrp_trains(\n",
    "        polygrp, img_id, rep_id, result, duration, offset, True\n",
    "    )\n",
    "polygrp_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find coincident activation times of neuron 1 (key=1) between the two PNGs\n",
    "times_0 = polygrp_patterns[0][1]\n",
    "times_1 = polygrp_patterns[1][1]\n",
    "\n",
    "# Match times where neuron 1 fires at the same time in both PNGs\n",
    "coincident_times = []\n",
    "for t0 in times_0:\n",
    "    diffs = np.abs(times_1 - t0)\n",
    "    idx = np.argmin(diffs)\n",
    "    if diffs[idx] < 1.0:\n",
    "        coincident_times.append(t0)\n",
    "\n",
    "coincident_times = np.array(coincident_times)\n",
    "print(f\"Coincident activation times of neuron 1: {coincident_times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build bounding boxes for each coincident activation, matched to PNG temporal span\n",
    "dy = 0.08\n",
    "\n",
    "bb_coords: list[list[dict]] = []  # bb_coords[i_png][j_activation]\n",
    "for i, polygrp in enumerate(polygrps_sel[:2]):\n",
    "    bbs = []\n",
    "    times_i = polygrp_patterns[i][1]\n",
    "    for t_coinc in coincident_times:\n",
    "        # Find the activation index in this PNG closest to the coincident time\n",
    "        idx = np.argmin(np.abs(times_i - t_coinc))\n",
    "        # Get spike times for all 3 neurons at this activation index\n",
    "        nrn_times = [polygrp_patterns[i][n][idx] for n in range(3)]\n",
    "        t_min = min(nrn_times)\n",
    "        t_max = max(nrn_times)\n",
    "        width = t_max - t_min\n",
    "        bbs.append({'xy': (t_min - 2, 0 - dy), 'width': width + 4, 'height': 2 + 2 * dy})\n",
    "    bb_coords.append(bbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 1, figsize=(5.5, 3))\n",
    "axes = np.atleast_1d(axes)\n",
    "\n",
    "xmin = 0\n",
    "xwidth = duration\n",
    "plot_kwargs = {\n",
    "    'markeredgewidth': 2/3, 'marker': 'o', 'markersize': 3\n",
    "}\n",
    "\n",
    "focal_color = 'C2'\n",
    "for i, polygrp in enumerate(polygrps_sel[:len(axes)]):\n",
    "    polygrp_id = polydb.find_idx(polygrp, polygrps)\n",
    "\n",
    "    ax = axes[i]\n",
    "    xlabel = '' if i < 1 else 'Time [ms]'\n",
    "    viz.plot_raster(\n",
    "        ops.select_nrns(spike_patterns[i], [1]), xwidth, xmin, alpha=1, axes=ax,\n",
    "        markerfacecolor='none', color=focal_color, xlabel='', **plot_kwargs\n",
    "    )\n",
    "    viz.plot_raster(\n",
    "        ops.select_nrns(polygrp_patterns[i], [1]), xwidth, xmin, alpha=1, axes=ax,\n",
    "        markerfacecolor=focal_color, color=focal_color, xlabel='', **plot_kwargs\n",
    "    )\n",
    "    plot_raster_row(\n",
    "        ops.select_nrns(spike_patterns[i], [0, 2]),\n",
    "        ops.select_nrns(polygrp_patterns[i], [0, 2]),\n",
    "        polygrp, ax, duration, xmin,\n",
    "        xlabel=xlabel, **plot_kwargs\n",
    "    )\n",
    "    yticks = ax.get_yticks()\n",
    "    ytick_labels = ax.get_yticklabels()\n",
    "    for ytick, label in zip(yticks, ytick_labels):\n",
    "        if ytick == 1:\n",
    "            label.set_color(focal_color)\n",
    "    # Draw bounding boxes for all coincident activations\n",
    "    for bb in bb_coords[i]:\n",
    "        rect = Rectangle(**bb, linewidth=1, edgecolor=colors[1], facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    ax.set_xticks(np.arange(xmin, xwidth + 50, 50))\n",
    "    # Attach PNG ID next to the last bounding box\n",
    "    if bb_coords[i]:\n",
    "        last_rect = Rectangle(**bb_coords[i][-1])\n",
    "        ax.text(last_rect.get_bbox().xmax + 4, 1.2, f'PNG ID: #{polygrp_id}', fontsize='x-small', ha='left')\n",
    "\n",
    "f.tight_layout()\n",
    "viz.save_figure(f, OUTPUT_DIR / \"fig17_png_rasters.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
