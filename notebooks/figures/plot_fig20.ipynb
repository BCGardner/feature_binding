{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oscillation analysis: HFB onsets\n",
    "\n",
    "Here we determine if the activation times of PNGs are associated with background rhythmic activity of excitatory neurons.\n",
    "\n",
    "**Dependencies:**\n",
    "\n",
    "Spike recordings, PNG detection and significance testing:\n",
    "- Note that recorded spike trains are non-deterministic: **results may differ from manuscript**\n",
    "- Takes ~1 hr (AMD Ryzen 9 5900X, 64GB RAM) to run the entire workflow\n",
    "- Same as the dependencies in `plot_fig19.ipynb`\n",
    "```bash\n",
    "./scripts/run_main_workflow.py experiments/n3p2/train_n3p2_lrate_0_04_181023 31 --layers 4 --configfile config/workflow/config_onsets.yaml --chkpt -1 --subdir onsets --rule significance -v\n",
    "```\n",
    "\n",
    "**Methods**\n",
    "\n",
    "Two integration methods explored for determining population activity: either $A^l(t)$ (global) or $A^l(t, \\vec{p})$ at position $\\vec{p}$ (localised).\n",
    "\n",
    "**Procedure**\n",
    "\n",
    "- Oscillations are calculated from the spatiotemporal recordings of EXC neurons in layer L3.\n",
    "- A bin size / averaging window in the interval $\\Delta T = [1, 5]$ ms is selected.\n",
    "- The localised activity $A^l(t, \\vec{p}_k)$ is determined w.r.t. a PNG, $k$ as follows:\n",
    "    1. The activity is determined w.r.t. the same layer as the initial, low-level neuron $i$ in layer $l$.\n",
    "    2. The weighted average of the number of spikes fired per neuron in $l$ over $\\Delta T$ is taken at each time point $t \\in [\\Delta T, T]$, centered about $\\vec{p}_i$.\n",
    "    3. This is divided by $\\Delta T$ to give the (instantaneous) population activity at each point in time $t$.\n",
    "- This is simplified if the global activity is instead considered: no need to compute separate $A^l(t)$ for each PNG $k$.\n",
    "\n",
    "**Plots**\n",
    "\n",
    "- The localised population activity $A^l(t, \\vec{p}_k)$ is plotted for a PNG $k$ starting in layer $l=3$: in response to two different shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Iterable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "import hsnn.analysis.png.db as polydb\n",
    "from hsnn.analysis.png import postproc, stats\n",
    "from hsnn import analysis, ops, simulation, utils, viz\n",
    "from hsnn.core import SpikeRecord\n",
    "from hsnn.utils import handler\n",
    "\n",
    "pidx = pd.IndexSlice\n",
    "OUTPUT_DIR = utils.io.BASE_DIR / \"out/figures/fig20\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "colors = prop_cycle.by_key()[\"color\"]\n",
    "\n",
    "viz.setup_journal_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Select experiment\n",
    "\n",
    "Load representative trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"n3p2/train_n3p2_lrate_0_04_181023\"\n",
    "\n",
    "expt = handler.ExperimentHandler(logdir)\n",
    "dataset_name = Path(logdir).parent.name\n",
    "print(f\"Target dataset: {dataset_name}\")\n",
    "# Get relevant, representative Trials\n",
    "df = expt.get_summary(-1)\n",
    "closest_trials = expt.index_to_dir[handler.get_closest_samples(df)]\n",
    "closest_trials.drop([(0, 0), (0, 20), (20, 0)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load data\n",
    "\n",
    "Including Trial, spike records, HFB DB, detected PNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect TrialsDict\n",
    "model_type = \"ALL\"\n",
    "analysis_type = \"onsets\"\n",
    "states = (\"post\",)\n",
    "\n",
    "print(f\"Selected network type: '{model_type}'; results: '{analysis_type}'\\n\")\n",
    "trials_dict = expt.metadata.get_trials_dict(model_type)\n",
    "\n",
    "# View relevant trials\n",
    "trial_names = trials_dict[analysis_type]\n",
    "print(\"# Trials to analyse:\")\n",
    "pprint([expt[trial_name] for trial_name in trial_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_id = \"TrainSNN_eb0d4_00031\"\n",
    "state = \"post\"\n",
    "subdir = \"onsets\"\n",
    "offset = 0.0\n",
    "num_reps = 10\n",
    "\n",
    "# Get representative Trial\n",
    "trial = expt[trial_id]\n",
    "print(trial)\n",
    "\n",
    "# Get relevant spike records\n",
    "result = handler.load_results(trial, state, subdir=subdir)[state].sel(\n",
    "    rep=range(num_reps)\n",
    ")\n",
    "duration: float = result.item(0).duration - offset\n",
    "assert len(result.rep) == 10\n",
    "print(f\"\\nduration={duration}; offset={offset}; num_reps={num_reps}\")\n",
    "\n",
    "# Load imageset and labels[, optionally with injected Gaussian noise]\n",
    "cfg = trial.config\n",
    "imageset, labels = utils.io.get_dataset(\n",
    "    cfg[\"training\"][\"data\"], return_annotations=True\n",
    ")\n",
    "\n",
    "# Get relevant HFB database\n",
    "database = handler.load_detections(trial, state, subdir=subdir)[state]\n",
    "print(f\"Loaded HFB database '{Path(database.path).relative_to(utils.io.BASE_DIR)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Restore Network and get refined PNGs\n",
    "For inspection of ground-truth axonal conduction delays, weights, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = simulation.Simulator.from_config(cfg)\n",
    "if state == \"post\":\n",
    "    sim.restore(trial.checkpoints[-1].store_path)\n",
    "    print(f\"Restoring from checkpoint '{trial.checkpoints[-1].store_path.relative_to(utils.io.BASE_DIR)}'\")\n",
    "syn_params: pd.DataFrame = sim.network.get_syn_params()\n",
    "syn_params = syn_params.loc[pidx[slice(None), (\"FF\", \"E2E\")], :].sort_index(\n",
    "    inplace=False\n",
    ")\n",
    "\n",
    "# Get detected PNGs (final layer)\n",
    "polygrps = polydb.get_polygrps(database, syn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Get inference / detection metrics\n",
    "\n",
    "Including the following:\n",
    "- Single-neuron specific information\n",
    "- PNG performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get single-neuron specific information measures for a target per side (convex)\n",
    "target = 1\n",
    "\n",
    "# Firing rates of EXC neuron across last two layers\n",
    "rates_array = analysis.infer_rates(\n",
    "    result.sel(layer=[3, 4], nrn_cls=\"EXC\"), duration, offset\n",
    ")\n",
    "\n",
    "specific_measures: dict[str, dict[str, pd.DataFrame]] = {}\n",
    "for layer in tqdm([3, 4]):\n",
    "    specific_measures[layer] = analysis.get_specific_measures_side(\n",
    "        rates_array.sel(layer=layer), labels, target=target\n",
    "    )\n",
    "\n",
    "# Get PNG performance metrics per side\n",
    "occ_array = stats.get_occurrences_array(\n",
    "    polygrps, num_reps, len(imageset), index=1, duration=duration, offset=offset\n",
    ")\n",
    "metrics_side = stats.get_metrics_side(occ_array, labels, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Inspect a PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = \"left\"\n",
    "\n",
    "metrics_side[side].sort_values(\"score\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_id = polydb.find_matching_index([(3, 2889), (4, 1990), (4, 1927)], polygrps)\n",
    "if metrics_side[side].loc[png_id][\"score\"] < 0.9:\n",
    "    raise UserWarning(\n",
    "        f\"Selected PNG with ID {png_id} has a score below 0.9: {metrics_side[side].loc[png_id]['score']:.3f}\"\n",
    "    )\n",
    "\n",
    "polygrp = polygrps[png_id]\n",
    "occ_array.sel(png=png_id).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Population activity\n",
    "\n",
    "- Calculate global activity at each time point.\n",
    "- Select an (`img`, `rep`) for a focal PNG with high F1-score\n",
    "\n",
    "**Explore individual activity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot activity: positive and negative examples**\n",
    "\n",
    "With / without a left-convex boundary element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(\n",
    "    img: int,\n",
    "    imageset: Iterable,\n",
    "    nrn_id: int | None = None,\n",
    "    show_ticks: bool = False,\n",
    "    axes: plt.Axes | None = None,\n",
    "    **plot_kwargs,\n",
    ") -> plt.Axes:\n",
    "    axes = viz.imshow_cbar(imageset[img], attach_cbar=False, cmax=255, axes=axes)\n",
    "    # Optionally plot nrn location\n",
    "    if nrn_id is not None:\n",
    "        _plot_kwargs = dict(\n",
    "            marker=\"o\", markerfacecolor=colors[1], color=\"k\", markersize=8\n",
    "        )\n",
    "        _plot_kwargs.update(**plot_kwargs)\n",
    "        coord = np.asarray(analysis.get_coords(nrn_id)) * 2\n",
    "        axes.plot(*coord, **_plot_kwargs)\n",
    "    if not show_ticks:\n",
    "        axes.set_xticks([])\n",
    "        axes.set_yticks([])\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_reps = [(2, 2), (4, 0)]\n",
    "nrn_idx = 0\n",
    "duration = 200.0\n",
    "radius = 10\n",
    "nrn_id = polygrp.nrns[nrn_idx]\n",
    "layer = polygrp.layers[nrn_idx]\n",
    "\n",
    "population = analysis.Population(duration, bin_size=2)\n",
    "nrn_ids = sorted(population.get_local_ids(nrn_id, radius))\n",
    "\n",
    "recordings_dict = {}\n",
    "activity_dict = {}\n",
    "polygrp_trains_dict = {}\n",
    "for img, rep in imgs_reps:\n",
    "    record: SpikeRecord = result.sel(\n",
    "        rep=rep, img=img, layer=layer, nrn_cls=\"EXC\"\n",
    "    ).item()\n",
    "    recordings_dict[(img, rep)] = ops.select_nrns(record.spike_events, nrn_ids)\n",
    "    activity_dict[(img, rep)] = population.local_activity(\n",
    "        record.spike_events, nrn_id, radius=radius\n",
    "    )\n",
    "    polygrp_trains_dict[(img, rep)] = postproc.get_polygrp_trains(\n",
    "        polygrp, img, rep, result, duration\n",
    "    )\n",
    "\n",
    "population = analysis.Population(duration, bin_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydelims = min(nrn_ids), max(nrn_ids)\n",
    "xmax = 100\n",
    "dx = 20\n",
    "dy = 100\n",
    "plot_kwargs = {\"marker\": \"o\"}\n",
    "\n",
    "f, axes = plt.subplots(2, 2, figsize=(5.5, 3), sharex=True)\n",
    "\n",
    "# Row 0: Activity plots\n",
    "ax: plt.Axes\n",
    "ymax = 0\n",
    "for i, (ax, key) in enumerate(zip(axes[0], imgs_reps)):\n",
    "    img = key[0]\n",
    "    ax.plot(population.time_points, activity_dict[key], color=colors[0])\n",
    "    ylim = ax.get_ylim()\n",
    "    ymax = ylim[-1] if ylim[-1] > ymax else ymax\n",
    "    ax.set_ylim([0, ymax])\n",
    "    inset_axes_ = inset_axes(\n",
    "        ax,\n",
    "        width=\"40%\",\n",
    "        height=\"40%\",\n",
    "        bbox_to_anchor=(0.35, 0.25, 1, 1),\n",
    "        bbox_transform=ax.transAxes,\n",
    "        loc=\"center\",\n",
    "    )\n",
    "    plot_image(img, imageset, nrn_id=nrn_id, axes=inset_axes_, markersize=4)\n",
    "    if i > 0:\n",
    "        ax.set_yticklabels([])\n",
    "    else:\n",
    "        ax.set_ylabel(\"Activity [Hz]\")\n",
    "    ax.vlines(\n",
    "        polygrp_trains_dict[key][nrn_idx],\n",
    "        0,\n",
    "        ymax,\n",
    "        colors=colors[1],\n",
    "        linestyles=\"dashed\",\n",
    "    )\n",
    "\n",
    "# Row 1: Raster plots\n",
    "for i, (ax, key) in enumerate(zip(axes[1], imgs_reps)):\n",
    "    viz.plot_raster(\n",
    "        recordings_dict[key],\n",
    "        xmax,\n",
    "        markerfacecolor=\"gray\",\n",
    "        color=\"gray\",\n",
    "        markeredgewidth=0,\n",
    "        markersize=2,\n",
    "        axes=ax,\n",
    "        **plot_kwargs,\n",
    "    )\n",
    "    viz.plot_raster(\n",
    "        {polygrp.nrns[nrn_idx]: polygrp_trains_dict[key][nrn_idx]},\n",
    "        xmax,\n",
    "        markerfacecolor=colors[1],\n",
    "        color=\"k\",\n",
    "        markeredgewidth=2 / 3,\n",
    "        axes=ax,\n",
    "        markersize=4,\n",
    "        **plot_kwargs,\n",
    "    )\n",
    "    ymin, ymax = (ydelims[0] // dy) * dy, (ydelims[1] // dy + 1) * dy\n",
    "    # ymin, ymax = 2000, 3500\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    if i > 0:\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_ylabel(\"\")\n",
    "    else:\n",
    "        ax.set_xlim([0, xmax])\n",
    "        ax.set_xticks(np.arange(0, xmax + dx, dx))\n",
    "# f.subplots_adjust(wspace=0.15)\n",
    "\n",
    "# Save figure\n",
    "filedir = OUTPUT_DIR / \"fig_png_onset_activity_n3p2.pdf\"\n",
    "viz.save_figure(f, filedir, overwrite=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
