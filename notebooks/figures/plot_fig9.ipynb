{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information analysis: N3P2 and N4P2\n",
    "\n",
    "Single-neuron information analysis and informative-neuron counts for convex boundary contour elements.\n",
    "\n",
    "This plots Fig 9 and supplementary S1 Fig.\n",
    "\n",
    "**Objectives**\n",
    "\n",
    "- Measure information conveyed by single L4 neurons regarding convex-boundary contour elements\n",
    "- Compare performance of different network architectures (combination of FF, LAT and FB)\n",
    "- Compare pre- vs. post-trained networks for N3P2 and N4P2 datasets\n",
    "- Count most informative neurons (maximum conveyed per side) across network architectures / datasets\n",
    "\n",
    "**Dependencies:**\n",
    "\n",
    "---\n",
    "\n",
    "A) Gather inference spike recordings:\n",
    "- Inference spike recordings for N3P2 & N4P2: both before and after network training\n",
    "- Depends on N3P2 workflows (with and without the `--chkpt -1` argument):\n",
    "    - `./scripts/run_main_workflow.py experiments/n3p2/train_n3p2_lrate_0_04_181023 0 1 3 4 5 7 8 9 31 --rule inference -v`\n",
    "- Depends on N4P2 workflows (with and without the `--chkpt -1` argument):\n",
    "    - `./scripts/run_main_workflow.py experiments/n4p2/train_n4p2_lrate_0_02_181023 0 1 3 4 5 7 12 15 29 --rule inference -v`\n",
    "\n",
    "---\n",
    "\n",
    "B) Compute information measures:\n",
    "\n",
    "- Add `--target 0` to do a parallel analysis regarding concave selectivity (S1 Figure)\n",
    "\n",
    "i) For N3P2:\n",
    "```bash\n",
    "for arch in FF SEMI ALL; do\n",
    "    ./scripts/figures/compute_information.py ./experiments/n3p2/train_n3p2_lrate_0_04_181023 $arch\n",
    "done\n",
    "```\n",
    "ii) and N4P2:\n",
    "```bash\n",
    "for arch in FF SEMI ALL; do\n",
    "    ./scripts/figures/compute_information.py ./experiments/n4p2/train_n4p2_lrate_0_02_181023 $arch\n",
    "done\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Plots**\n",
    "\n",
    "- Panel A: rank-order single neuron information curves\n",
    "- Panel B: number of selective neurons (exceeding 2/3 threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from hsnn import viz\n",
    "from hsnn.utils import handler, io\n",
    "\n",
    "pidx = pd.IndexSlice\n",
    "RESULTS_DIR = io.BASE_DIR / \"out/figures/information\"\n",
    "OUTPUT_DIR = io.BASE_DIR / \"out/figures/fig9\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "class DataSet(Enum):\n",
    "    N3P2 = 1\n",
    "    N4P2 = 2\n",
    "\n",
    "\n",
    "def load_measures(\n",
    "    results_dir: Path, noise: int = 0, target: int = 1\n",
    ") -> dict[str, dict[str, np.ndarray]]:\n",
    "    \"\"\"Loads ranked single neuron information measures.\n",
    "\n",
    "    Args:\n",
    "        results_dir (Path): Location of pre-computed measures.\n",
    "        noise (int, optional): Noise amplitude of inference recordings. Defaults to 0.\n",
    "        target (int, optional): Target boundary conformation. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, dict[str, np.ndarray]]: Mapping from network architecture, and then state.\n",
    "        Each element is an NDArray[float] of ranked measures, shape (num_trials x num_sides, num_nrns)\n",
    "    \"\"\"\n",
    "    parts = [\"information\", \"max\"]\n",
    "    parts += [\"convex\"] if target == 1 else [\"concave\"]\n",
    "    fname = io.formatted_name(\"_\".join(parts), \"pkl\", noise=noise)\n",
    "    return io.load_pickle(results_dir / fname)\n",
    "\n",
    "\n",
    "def plot_grid(state_measures_map: dict, axes: plt.Axes) -> plt.Axes:\n",
    "    xticks = np.arange(1, 4096 + 1)\n",
    "\n",
    "    axes.plot(xticks, state_measures_map[\"pre\"].mean(axis=0), label=\"Untrained\", ls=\":\")\n",
    "    axes.plot(xticks, state_measures_map[\"post\"].mean(axis=0), label=\"Trained\", ls=\"-\")\n",
    "    # axes = viz.plot_errorband(\n",
    "    #     state_measures_map[\"pre\"].T, label=\"Untrained\", ls=\":\", xticks=xticks, axes=axes\n",
    "    # )\n",
    "    # axes = viz.plot_errorband(\n",
    "    #     state_measures_map[\"post\"].T, label=\"Trained\", ls=\"-\", xticks=xticks, axes=axes\n",
    "    # )\n",
    "    axes.set_xlim(xticks[0], xticks[-1])\n",
    "    axes.set_xscale(\"log\")\n",
    "    axes.set_ylim([0, 1.05])\n",
    "    axes.grid(True)\n",
    "    # axes.set_title(f'Single Neuron Information Analysis');\n",
    "    return axes\n",
    "\n",
    "\n",
    "viz.setup_journal_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load measures from both experiments (N3P2, N4P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 0  # Set target=1 for convex, or target=0 for concave\n",
    "measures_dict: dict[DataSet, dict[str, dict[str, np.ndarray]]] = {}\n",
    "\n",
    "logdirs = {\n",
    "    DataSet.N3P2: \"n3p2/train_n3p2_lrate_0_04_181023\",\n",
    "    DataSet.N4P2: \"n4p2/train_n4p2_lrate_0_02_181023\",\n",
    "}\n",
    "for dataset, logdir in logdirs.items():\n",
    "    expt = handler.ExperimentHandler(logdir)\n",
    "    dataset_name = Path(logdir).parent.name\n",
    "    measures_dict[dataset] = load_measures(RESULTS_DIR / dataset_name, target=target)\n",
    "    print(f\"Loaded '{dataset_name}' measures from '{RESULTS_DIR / dataset_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1: Information analysis\n",
    "\n",
    "**Styles:**\n",
    "\n",
    "- Aim for easy comparison across architectures per dataset\n",
    "- Try plotting all trends into one plot with untrained network as FF + LAT + FB\n",
    "- If this is unclear, use a separate subplot per architecture and highlight pre- vs post-training\n",
    "- Try with / without error bars\n",
    "\n",
    "**Layout:**\n",
    "\n",
    "- Cols: N3P2, N4P2\n",
    "- Rows: different architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archs = [\"FF\", \"SEMI\", \"ALL\"]\n",
    "arch_desc_mapping = {\"FF\": \"FF\", \"SEMI\": \"FF+LAT\", \"ALL\": \"FF+LAT+FB\"}\n",
    "width = 5.5\n",
    "height = 4\n",
    "\n",
    "f, axes = plt.subplots(3, 2, figsize=(width, height))\n",
    "for row, arch in enumerate(archs):\n",
    "    for col, dataset in enumerate(DataSet):\n",
    "        ax: plt.Axes = axes[row, col]\n",
    "        state_measures_map = measures_dict[dataset][arch]\n",
    "        plot_grid(state_measures_map, ax)\n",
    "        # ticks, labels\n",
    "        if row == 0:\n",
    "            ax.set_title(dataset.name, size=10, pad=10, fontweight=\"bold\")\n",
    "        if row < 2:\n",
    "            ax.set_xticklabels([])\n",
    "        else:\n",
    "            ax.set_xlabel(\"Neuron rank #\")\n",
    "        if col > 0:\n",
    "            ax.set_yticklabels([])\n",
    "        else:\n",
    "            ax.set_ylabel(r\"$\\mathcal{I}\\; (s, \\vec{R})$\")\n",
    "            ax.text(\n",
    "                -0.4,\n",
    "                0.5,\n",
    "                rf\"{arch_desc_mapping[arch]}\",\n",
    "                size=10,\n",
    "                horizontalalignment=\"right\",\n",
    "                verticalalignment=\"center\",\n",
    "                transform=ax.transAxes,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "        if ax == axes[-1, -2]:\n",
    "            if target == 1:\n",
    "                ax.legend(fontsize=\"x-small\", loc=\"lower left\")\n",
    "            else:\n",
    "                ax.legend(fontsize=\"x-small\", loc=\"upper right\")\n",
    "        # ax.set_xlim([None, 1.5e3])\n",
    "        ax.set_xlim([1, 4096])\n",
    "f.tight_layout()\n",
    "\n",
    "conformation = \"convex\" if target == 1 else \"concave\"\n",
    "parts = [\"fig\", \"information\", conformation, \"datasets\"]\n",
    "fname = \"_\".join(parts) + \".pdf\"\n",
    "fpath = OUTPUT_DIR / fname\n",
    "viz.save_figure(f, fpath, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2: number of most selective neurons\n",
    "\n",
    "**Styles:**\n",
    "\n",
    "- Bar charts: N3P2, N4P2\n",
    "- Plot number of neurons with I(s, R) > 0.9 or 2/3 per network architecture\n",
    "- Untrained architecture can be FF + LAT + FB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_num_selective(\n",
    "    info_measures: np.ndarray, threshold: float = 2 / 3.0\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Compute mean and SEM of informative neuron counts across trials.\n",
    "\n",
    "    Args:\n",
    "        info_measures: Array of shape (n_trials, n_neurons).\n",
    "        threshold: Information threshold for \"informative\" neurons.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (mean count, SEM).\n",
    "    \"\"\"\n",
    "    if info_measures.ndim == 2:\n",
    "        counts = np.sum(info_measures >= threshold, axis=1)\n",
    "        return counts.mean(), counts.std() / np.sqrt(len(counts))\n",
    "    elif info_measures.ndim == 1:\n",
    "        count = (info_measures > threshold).sum()\n",
    "        return float(count), 0.0\n",
    "    else:\n",
    "        raise ValueError(info_measures.shape)\n",
    "\n",
    "\n",
    "def get_num_selective_dataset(\n",
    "    measures_arch: dict[str, dict[str, np.ndarray]], threshold: float = 2 / 3.0\n",
    ") -> tuple[list[str], dict[str, list[float]], dict[str, list[float]]]:\n",
    "    \"\"\"Get mean counts and SEMs for each architecture and state.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (archs, means_dict, sems_dict).\n",
    "    \"\"\"\n",
    "    means = {\"pre\": [], \"post\": []}\n",
    "    sems = {\"pre\": [], \"post\": []}\n",
    "    archs = []\n",
    "    for arch, measures_state in measures_arch.items():\n",
    "        archs.append(arch)\n",
    "        for state, info_measures in measures_state.items():\n",
    "            mean, sem = _get_num_selective(info_measures, threshold)\n",
    "            means[state].append(mean)\n",
    "            sems[state].append(sem)\n",
    "    return archs, means, sems\n",
    "\n",
    "\n",
    "def plot_number_selective_neurons(\n",
    "    num_selective_nrns: dict[str, npt.ArrayLike],\n",
    "    sems: dict[str, npt.ArrayLike],\n",
    "    dataset_name: str,\n",
    "    axes: plt.Axes | None = None,\n",
    ") -> plt.Axes:\n",
    "    axes = viz.base.setup_axes(axes)\n",
    "    axes.grid(axis=\"y\")\n",
    "    axes.yaxis.set_major_locator(MaxNLocator(nbins=5, integer=True))\n",
    "\n",
    "    x = np.arange(len(archs))\n",
    "    y1 = num_selective_nrns[\"pre\"]\n",
    "    y2 = num_selective_nrns[\"post\"]\n",
    "    sem1 = sems[\"pre\"]\n",
    "    sem2 = sems[\"post\"]\n",
    "    labels = [arch_desc_mapping[label] for label in archs]\n",
    "\n",
    "    # Width of a bar\n",
    "    width = 0.4\n",
    "    factor = 1 / 2 + 0.05\n",
    "\n",
    "    axes: plt.Axes\n",
    "    bars1 = axes.bar(\n",
    "        x - width * factor, y1, width, yerr=sem1, label=\"Untrained\", zorder=3, capsize=3\n",
    "    )\n",
    "    bars2 = axes.bar(\n",
    "        x + width * factor, y2, width, yerr=sem2, label=\"Trained\", zorder=3, capsize=3\n",
    "    )\n",
    "\n",
    "    # Add percentage labels above bars (without error values)\n",
    "    num_total = 4096\n",
    "    for bar, val, sem_val in zip(bars1, y1, sem1):\n",
    "        pct = val / num_total * 100\n",
    "        if pct > 0:\n",
    "            axes.annotate(\n",
    "                f\"{pct:.1f}%\",\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height() + sem_val + 2),\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=\"x-small\",\n",
    "            )\n",
    "    for bar, val, sem_val in zip(bars2, y2, sem2):\n",
    "        pct = val / num_total * 100\n",
    "        if pct > 0:\n",
    "            axes.annotate(\n",
    "                f\"{pct:.1f}%\",\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height() + sem_val + 2),\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=\"x-small\",\n",
    "            )\n",
    "\n",
    "    axes.set_title(f\"{dataset_name}\", fontweight=\"bold\", fontsize=10)\n",
    "    axes.set_xticks(x)\n",
    "    axes.set_xticks(x, labels, fontsize=10, rotation=45, horizontalalignment=\"right\")\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2 / 3\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(5.5, 3), sharey=True)\n",
    "\n",
    "for i, (dataset, measures_arch) in enumerate(measures_dict.items()):\n",
    "    archs, num_selective_nrns, sems = get_num_selective_dataset(\n",
    "        measures_dict[dataset], threshold=threshold\n",
    "    )\n",
    "    ax = plot_number_selective_neurons(\n",
    "        num_selective_nrns, sems, dataset.name, axes=axes[i]\n",
    "    )\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"# informative neurons\")\n",
    "else:\n",
    "    ax.legend(loc=(\"upper right\" if target == 1 else \"upper left\"))\n",
    "ax.set_ylim(0, (420 if target == 1 else 100))\n",
    "f.tight_layout()\n",
    "\n",
    "parts = [\"fig\", \"informative_neurons\", conformation, \"datasets\"]\n",
    "fname = \"_\".join(parts) + \".pdf\"\n",
    "fpath = OUTPUT_DIR / fname\n",
    "viz.save_figure(f, fpath, overwrite=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
